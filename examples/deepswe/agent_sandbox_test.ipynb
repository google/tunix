{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d4c4a6",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "glcoud\n",
    "kubectl\n",
    "uv\n",
    "\n",
    "### Create a GKE Cluster\n",
    "\n",
    "These are the steps for a GKE Standard cluster. You can also use an Autopilot cluster, which handles\n",
    "scaling and node pools for you.\n",
    "\n",
    "```bash\n",
    "export PROJECT_ID=$(gcloud config get project)\n",
    "export CLUSTER_NAME=tunix-demo\n",
    "export LOCATION=us-west1\n",
    "export NODE_POOL_NAME=\"gvisor-node-pool\"\n",
    "export MACHINE_TYPE=\"n2-standard-8\"\n",
    "export NUM_NODES=1\n",
    "```\n",
    "\n",
    "Create a Standard GKE Cluster. This may take a few minutes:\n",
    "\n",
    "```bash\n",
    "gcloud container clusters create ${CLUSTER_NAME} \\\n",
    "    --location=${LOCATION}\n",
    "```\n",
    "\n",
    "Creating the cluster will automatically retreive the cluster credentials for you which will allow\n",
    "you to run `kubectl` commands. If you need to get them again, run:\n",
    "\n",
    "```bash\n",
    " gcloud container clusters get-credentials ${CLUSTER_NAME} --location ${LOCATION} --project ${PROJECT_ID}\n",
    "```\n",
    "\n",
    "Create a gVisor node pool. This may take a few minutes:\n",
    "\n",
    "```bash\n",
    "gcloud container node-pools create ${NODE_POOL_NAME} \\\n",
    "  --cluster=${CLUSTER_NAME} \\\n",
    "  --location=${LOCATION} \\\n",
    "  --machine-type=${MACHINE_TYPE} \\\n",
    "  --image-type=cos_containerd \\\n",
    "  --sandbox type=gvisor \\\n",
    "  --num-nodes=${NUM_NODES} \\\n",
    "  --enable-autoscaling \\\n",
    "  --min-nodes=1 \\\n",
    "  --max-nodes=5 \\\n",
    "  --node-labels=\"cloud.google.com/gke-nodepool=${NODE_POOL_NAME}\"\n",
    "```\n",
    "\n",
    "### Install Agent-Sandbox Controller into GKE Cluster\n",
    "\n",
    "Instructions are copied from https://github.com/kubernetes-sigs/agent-sandbox/releases:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f https://github.com/kubernetes-sigs/agent-sandbox/releases/download/v0.1.1/manifest.yaml\n",
    "kubectl apply -f https://github.com/kubernetes-sigs/agent-sandbox/releases/download/v0.1.1/extensions.yaml\n",
    "```\n",
    "\n",
    "### Install Notebook Dependecies\n",
    "\n",
    "Create virtual environment in the root `~/tunix` directory using commands below.\n",
    "In your IDE select that `.venv/bin/python` as the Python Interpreter and Kernel for this notebook.\n",
    "\n",
    "Note that the `assistant` responses are mocked in this notebook, so this notebook does not\n",
    "require a TPU. For actual use follow instructions for creating and connecting to a TPU in\n",
    "`~/tunix/examples/README.rst`.\n",
    "\n",
    "We pin to the same Python version as the Jupyter server in the TPU.\n",
    "We use `uv` because this is the method preferred by R2E-Gym.\n",
    "\n",
    "Run these commands in your terminal at the project root, not in this notebook:\n",
    "\n",
    "```bash\n",
    "sudo apt install python3.12-venv\n",
    "uv python pin 3.12.9\n",
    "uv sync -U\n",
    "```\n",
    "\n",
    "Activate the virtual environment, and install dependencies specific to this notebook:\n",
    "\n",
    "```bash\n",
    "source ~/tunix/.venv/bin/activate\n",
    "uv pip install -U ipykernel ipywidgets kubernetes k8s-agent-sandbox\n",
    "```\n",
    "\n",
    "#### Install Fork of R2E-Gym\n",
    "\n",
    "Install from a specific git commit\n",
    "https://github.com/R2E-Gym/R2E-Gym/commit/36c2497d2b238bf02f1c7d6e5ba2e7ed9911595e with the\n",
    "agentic-sandbox changes included.\n",
    "\n",
    "```bash\n",
    "uv pip install \"git+https://github.com/R2E-Gym/R2E-Gym.git@36c2497d2b238bf02f1c7d6e5ba2e7ed9911595e\"\n",
    "```\n",
    "\n",
    "These code changes live on a separate fork of R2E-Gym. This is because R2E-Gym is not being\n",
    "actively maintained, so it is unlikely that these changes will be merged into main.\n",
    "\n",
    "<!-- Install local, editable version of R2E-Gym. Must first have the repo forked or cloned locally.\n",
    "\n",
    "```bash\n",
    "uv pip install -e ~/R2E-Gym\n",
    "```\n",
    "\n",
    "If installing from R2E-Gym main, you must upgrade the datasets version after installing R2E-Gym\n",
    "which pinned the datasets version to 2.19 which does not work with Python >=3.12.\n",
    "\n",
    "Note that R2E-Gym main does not support sandbox. You must use the above commit or a fork of it.\n",
    "\n",
    "```bash\n",
    "uv pip install -U datasets\n",
    "``` -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46265330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def get_uv_pip_list():\n",
    "    \"\"\"\n",
    "    Executes 'uv pip list' and captures the output.\n",
    "    Use ['uv', 'run', 'pip', 'list'] to force environment discovery.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['uv', 'pip', 'list'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing uv: {e.stderr}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The 'uv' executable was not found. Please ensure uv is installed.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_uv_pip_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e8c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "DATASET_CACHE = os.getenv('DATASET_CACHE', '~/scratch/dataset_cache')\n",
    "TASKS_TO_PROCESS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, cast\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"R2E-Gym/R2E-Gym-V1\",\n",
    "    split=\"train\",\n",
    "    cache_dir=DATASET_CACHE,\n",
    "    num_proc=32,\n",
    ")\n",
    "entries = []\n",
    "unique_images = set()\n",
    "for i, entry in enumerate(dataset):\n",
    "    # Cast entry to dict to satisfy Pylance\n",
    "    row = cast(dict[str, Any], entry)\n",
    "    if \"docker_image\" in row:\n",
    "        unique_images.add(row[\"docker_image\"])\n",
    "        entries.append(entry)\n",
    "    if i >= TASKS_TO_PROCESS - 1:\n",
    "        break\n",
    "unique_images = list(unique_images)\n",
    "print(f\"Found {len(unique_images)} unique Docker images to download\")\n",
    "IDS = [f\"task-{i}\" for i in range(len(entries))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client, config\n",
    "import os\n",
    "\n",
    "NODE_POOL_NAME = \"gvisor-node-pool\"\n",
    "\n",
    "os.environ[\"KUBECONFIG\"] = \"~/.kube/config\"\n",
    "os.environ[\"NODE_SELECTOR_KEY\"] = \"cloud.google.com/gke-nodepool\"\n",
    "# NB: change based on your node pool name\n",
    "os.environ[\"NODE_SELECTOR_VAL\"] = NODE_POOL_NAME\n",
    "\n",
    "config.load_kube_config()\n",
    "k8s_client = client.CoreV1Api()\n",
    "# k8s_client.list_namespace(timeout_seconds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db912576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from r2egym.agenthub.environment.env import EnvArgs, RepoEnv\n",
    "import os\n",
    "import r2egym\n",
    "\n",
    "print(r2egym.__file__)\n",
    "\n",
    "env_args = EnvArgs(ds=entries[0])\n",
    "env = RepoEnv(env_args, backend=\"kubernetes-sandbox\")\n",
    "# env = RepoEnv(env_args, backend=\"kubernetes\")\n",
    "\n",
    "try:\n",
    "    R2EGYM_PATH = os.path.dirname(r2egym.__file__)\n",
    "except Exception:\n",
    "    R2EGYM_PATH = \"\"\n",
    "\n",
    "R2EGYM_COMMAND_FILES = [\n",
    "    os.path.join(R2EGYM_PATH, \"agenthub/tools/file_editor.py\"),\n",
    "    os.path.join(R2EGYM_PATH, \"agenthub/tools/search.py\"),\n",
    "    os.path.join(R2EGYM_PATH, \"agenthub/tools/execute_bash.py\"),\n",
    "    os.path.join(R2EGYM_PATH, \"agenthub/tools/finish.py\"),\n",
    "]\n",
    "\n",
    "env.add_commands(cmd_files=R2EGYM_COMMAND_FILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453c301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, exit_code = env.runtime.run(\"ls -F /testbed\")\n",
    "\n",
    "if exit_code == \"0\":\n",
    "    print(\"Pod is responsive! Contents of /testbed:\")\n",
    "    print(output)\n",
    "else:\n",
    "    print(f\"Execution failed with error: {exit_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd49391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the tools loaded\n",
    "output, _ = env.runtime.run(\"ls -F /usr/local/bin/\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e186bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if the search tool is functional\n",
    "output, exit_code = env.runtime.run(\"search --help\")\n",
    "print(f\"Tool Exit Code: {exit_code}\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f028333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version and ability to import the codebase\n",
    "output, _ = env.runtime.run(\n",
    "    \"python --version && python -c 'import Orange; print(\\\"Orange version:\\\", Orange.__version__)'\")\n",
    "print(output)\n",
    "\n",
    "# Check the git state to ensure it's at the correct base commit\n",
    "output, _ = env.runtime.run(\"git rev-parse HEAD\")\n",
    "print(f\"Current commit in pod: {output.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea026b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pod details from the Kubernetes API\n",
    "def get_pods():\n",
    "\n",
    "    pod_list = k8s_client.list_namespaced_pod(\"default\")\n",
    "    for pod in pod_list.items:\n",
    "        print(\"%s\\t%s\\t%s\" % (pod.metadata.name,\n",
    "                              pod.status.phase,\n",
    "                              pod.status.pod_ip))\n",
    "\n",
    "\n",
    "get_pods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1233f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define LLM Output Parser for Mocks. Would need a more robust parser for prod.\n",
    "\n",
    "\n",
    "def parse_action(llm_output: str) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Parses XML-like format: <parameter name=key>value</parameter>\n",
    "    Returns dict like {'command': 'view', 'path': '/testbed'}\n",
    "    \"\"\"\n",
    "    args = {}\n",
    "    # Regex captures the key inside <parameter name=KEY> and the value inside the tags\n",
    "    matches = re.findall(\n",
    "        r'<parameter name=\"([^\"]+)\">(.*?)</parameter>', llm_output, re.DOTALL)\n",
    "\n",
    "    for key, value in matches:\n",
    "        args[key.strip()] = value.strip()\n",
    "\n",
    "    print(\"parse_action\", args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_mock_action(env, action_str: str):\n",
    "    \"\"\"\n",
    "    Maps parsed LLM actions to the corresponding tool execution command in the sandbox.\n",
    "    \"\"\"\n",
    "    args = parse_action(action_str)\n",
    "    command_type = args.get('command')\n",
    "\n",
    "    if not command_type:\n",
    "        print(f\"Error: No command found in mock response. Args: {args}\")\n",
    "        return\n",
    "\n",
    "    bash_cmd = \"\"\n",
    "\n",
    "    # Handle File Editor Tool (file_editor.py)\n",
    "    if command_type in ['view', 'create', 'str_replace', 'insert', 'undo_edit']:\n",
    "        bash_cmd = f\"file_editor --path {args.get('path', '')}\"\n",
    "        if 'view_range' in args: bash_cmd += f\" --view_range '{args['view_range']}'\"\n",
    "        if 'file_text' in args: bash_cmd += f\" --file_text '{args['file_text'].replace(\"'\", \"'\\\\''\")}'\"\n",
    "        if 'old_str' in args: bash_cmd += f\" --old_str '{args['old_str'].replace(\"'\", \"'\\\\''\")}'\"\n",
    "        if 'new_str' in args: bash_cmd += f\" --new_str '{args['new_str'].replace(\"'\", \"'\\\\''\")}'\"\n",
    "        if 'insert_line' in args: bash_cmd += f\" --insert_line {args['insert_line']}\"\n",
    "        bash_cmd += f\" {command_type}\"\n",
    "\n",
    "    # Handle Search Tool (search.py)\n",
    "    elif command_type == 'search':\n",
    "        bash_cmd = f\"search --search_term '{args.get('search_term', '').replace(\"'\", \"'\\\\''\")}' --path '{args.get('path', '.')}'\"\n",
    "\n",
    "    # Handle Execute Bash Tool (execute_bash.py)\n",
    "    elif command_type == 'execute_bash':\n",
    "        bash_cmd = f\"execute_bash '{args.get('bash_command', '').replace(\"'\", \"'\\\\''\")}'\"\n",
    "\n",
    "    # Handle Finish/Submit Tool (finish.py)\n",
    "    elif command_type == 'submit':\n",
    "        bash_cmd = f\"finish submit --result '{args.get('result', '').replace(\"'\", \"'\\\\''\")}'\"\n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown command: {command_type}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Executing in Sandbox: {bash_cmd}\")\n",
    "    output, exit_code = env.runtime.run(bash_cmd)\n",
    "    print(f\"--- Output (Exit: {exit_code}) ---\\n{output[:1000]}\\n----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc39080",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_responses = [\n",
    "    # Test 1: View directory structure using file_editor\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">view</parameter>\n",
    "    <parameter name=\"path\">/testbed</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 2: Search for a specific term using search tool\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">search</parameter>\n",
    "    <parameter name=\"search_term\">Orange</parameter>\n",
    "    <parameter name=\"path\">/testbed</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 3: Create a new Python file using file_editor\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">create</parameter>\n",
    "    <parameter name=\"path\">/testbed/verify_sandbox.py</parameter>\n",
    "    <parameter name=\"file_text\">import os\\nprint(\"Sandbox Verification: SUCCESS\")\\nprint(f\"Working Directory: {os.getcwd()}\")</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 4: Execute the newly created file using execute_bash\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">execute_bash</parameter>\n",
    "    <parameter name=\"bash_command\">python /testbed/verify_sandbox.py</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 5: Use str_replace to modify the file\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">str_replace</parameter>\n",
    "    <parameter name=\"path\">/testbed/verify_sandbox.py</parameter>\n",
    "    <parameter name=\"old_str\">Sandbox Verification: SUCCESS</parameter>\n",
    "    <parameter name=\"new_str\">Sandbox Verification: COMPLETED</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 6: Verify the edit by running it again\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">execute_bash</parameter>\n",
    "    <parameter name=\"bash_command\">python /testbed/verify_sandbox.py</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 7: Use insert to add a line at a specific position\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">insert</parameter>\n",
    "    <parameter name=\"path\">/testbed/verify_sandbox.py</parameter>\n",
    "    <parameter name=\"insert_line\">1</parameter>\n",
    "    <parameter name=\"new_str\">import sys</parameter>\n",
    "    </function>\n",
    "    \"\"\",\n",
    "    # Test 8: Final submission signal using finish tool\n",
    "    \"\"\"\n",
    "    <function>\n",
    "    <parameter name=\"command\">submit</parameter>\n",
    "    <parameter name=\"result\">All tools verified successfully.</parameter>\n",
    "    </function>\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for i, response in enumerate(mock_responses):\n",
    "    print(f\"\\n>>> Step {i+1} <<<\")\n",
    "    execute_mock_action(env, response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the runtime to delete the SandboxClaim, Sandbox, and Pod.\n",
    "# env.runtime.close()\n",
    "# print(\"Sandbox Claim deleted. Pod termination initiated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared Resource Cleanup (Deletes the Template for ALL runs using this image)\n",
    "# Run this only when you are done with all tasks for this Docker image.\n",
    "# env.runtime.delete_template()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
