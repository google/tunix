data:
  train_data: data/gsm8k/train.parquet
  eval_data: data/gsm8k/eval.parquet

model:
  name: meta-llama/Llama-3.2-1B-Instruct
  mesh:
    fsdp: 4
    tp: 1

train:
  max_prompt_length: 512
  max_response_length: 1024
  batch_size: 12
  num_batches: 8192
  num_epochs: 1
  save_interval_steps: 500
  eval_every_n_steps: 50
  ckpt_dir: /tmp/tunix/experiments/grpo/llama3p2_1b_gsm8k
  reward_fns:
    - reward_fn/gsm8k.py
  max_to_keep: 4
  trainer: grpo
  rollout:
    temperature: 0.9
    top_p: 1.0
    top_k: 50
  grpo:
    num_iterations: 1
    num_generations: 2
    beta: 0.08
    epsilon: 0.2
  optimizer:
    learning_rate: !!float 2e-6
    b1: 0.9
    b2: 0.99
    weight_decay: 0.0
    warmup_ratio: 0.01
    max_grad_norm: 1.0
