{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e585d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal Paligemma-style GRPO demo (SigLIP + Gemma with LoRA).\n",
    "# This uses a dummy image stream; replace with your VQA dataset.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Install\n",
    "\n",
    "# %%\n",
    "!pip install -q tensorboardX grain datasets pillow\n",
    "!pip install -q jaxtyping sentencepiece datasets grain tensorboardX tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143d546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/google/qwix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5fb4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/grads/tianjiao/tunix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Imports & paths\n",
    "\n",
    "# %%\n",
    "import os, numpy as np, jax, jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax\n",
    "\n",
    "from tunix.models.gemma3 import params as gemma3_params\n",
    "from tunix.models.gemma3 import model as gemma3_model\n",
    "from tunix.models.gemma import data as gemma_tokenizer_lib\n",
    "from tunix.models.siglip import params as siglip_params\n",
    "from tunix.models.siglip import model as siglip_model\n",
    "\n",
    "from tunix.generate import vlm_sampler as vlm_sampler_lib\n",
    "from tunix.rl.rollout import vlm_rollout as vlm_rollout_lib\n",
    "from tunix.rl import rl_cluster as rl_cluster_lib\n",
    "from tunix.rl.grpo.grpo_learner import GrpoConfig, GrpoLearner\n",
    "from tunix.rl.rewards import vqa_rewards as R\n",
    "from tunix.sft import metrics_logger\n",
    "from tunix.rl.rollout import base_rollout\n",
    "import qwix\n",
    "\n",
    "SIGLIP_DIR = \"/home/grads/tianjiao/checkpoints/siglip-so400m-patch14-384\"    # @title <-- put your safetensors dir\n",
    "GEMMA3_CKPT = \"gs://gemma-data/checkpoints/gemma3-4b-it\"  # @title\n",
    "\n",
    "WORKDIR = \"/home/grads/tianjiao/vlm_grpo\"\n",
    "os.makedirs(WORKDIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3bd3943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: cpu\n",
      "devices: [CpuDevice(id=0)]\n",
      "local_devices: [CpuDevice(id=0)]\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "JAX_PLATFORM_NAME: None\n"
     ]
    }
   ],
   "source": [
    "import os, jax\n",
    "print(\"backend:\", jax.default_backend())\n",
    "print(\"devices:\", jax.devices())\n",
    "print(\"local_devices:\", jax.local_devices())\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"JAX_PLATFORM_NAME:\", os.environ.get(\"JAX_PLATFORM_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e327e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Tokenizer, mesh, configs\n",
    "\n",
    "# %%\n",
    "tokenizer = gemma_tokenizer_lib.GemmaTokenizer()\n",
    "mesh = jax.make_mesh((1,1), (\"fsdp\",\"tp\"))\n",
    "\n",
    "MAX_PROMPT_LEN = 256\n",
    "MAX_GEN_STEPS = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b750e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`StandardCheckpointHandler` expects a target tree to be provided for restore. Not doing so is generally UNSAFE unless you know the present topology to be the same one as the checkpoint was saved under.\n",
      "E0907 01:26:48.882745  441336 google_auth_provider.cc:188] Could not find the credentials file in the standard gcloud location [/home/grads/tianjiao/.config/gcloud/application_default_credentials.json]. You may specify a credentials file using $GOOGLE_APPLICATION_CREDENTIALS, or to use Google application default credentials, run: gcloud auth application-default login\n",
      "WARNING:absl:`StandardCheckpointHandler` expects a target tree to be provided for restore. Not doing so is generally UNSAFE unless you know the present topology to be the same one as the checkpoint was saved under.\n"
     ]
    }
   ],
   "source": [
    "# ## Load models (text + vision) and apply LoRA\n",
    "\n",
    "# %%\n",
    "gcfg = gemma3_model.Gemma3Config.gemma3_4b()\n",
    "gemma_text = gemma3_params.create_model_from_checkpoint(GEMMA3_CKPT, gcfg, mesh)\n",
    "ref_text   = gemma3_params.create_model_from_checkpoint(GEMMA3_CKPT, gcfg, mesh)\n",
    "\n",
    "lora_provider = qwix.LoraProvider(\n",
    "    module_path=\".*q_einsum|.*kv_einsum|.*attn_vec_einsum|.*gate_proj|.*up_proj|.*down_proj\",\n",
    "    rank=32, alpha=32.0,\n",
    ")\n",
    "lora_text = qwix.apply_lora_to_model(gemma_text, lora_provider, **gemma_text.get_model_input())\n",
    "\n",
    "with mesh:\n",
    "  st = nnx.state(lora_text)\n",
    "  ps = nnx.get_partition_spec(st)\n",
    "  nnx.update(lora_text, jax.lax.with_sharding_constraint(st, ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134b76e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No safetensors in /home/grads/tianjiao/siglip-so400m-patch14-384",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m scfg = siglip_model.SigLIPConfig.so400m_patch14_384()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m siglip = \u001b[43msiglip_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model_from_safe_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSIGLIP_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/tunix/tunix/models/siglip/params.py:171\u001b[39m, in \u001b[36mcreate_model_from_safe_tensors\u001b[39m\u001b[34m(file_dir, config, mesh)\u001b[39m\n\u001b[32m    169\u001b[39m files = \u001b[38;5;28mlist\u001b[39m(epath.Path(file_dir).expanduser().glob(\u001b[33m\"\u001b[39m\u001b[33m*.safetensors\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo safetensors in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# 1) Config: derive from HF config.json if not supplied\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: No safetensors in /home/grads/tianjiao/siglip-so400m-patch14-384"
     ]
    }
   ],
   "source": [
    "\n",
    "scfg = siglip_model.SigLIPConfig.so400m_patch14_384()\n",
    "siglip = siglip_params.create_model_from_safe_tensors(SIGLIP_DIR, scfg, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837046f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61c280",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "cache_cfg = vlm_sampler_lib.CacheConfig(\n",
    "    cache_size=MAX_PROMPT_LEN + MAX_GEN_STEPS + 256,\n",
    "    num_layers=gcfg.num_layers,\n",
    "    num_kv_heads=gcfg.num_kv_heads,\n",
    "    head_dim=gcfg.head_dim,\n",
    ")\n",
    "sampler = vlm_sampler_lib.VLMSampler(\n",
    "    transformer=lora_text,\n",
    "    vision_encoder=siglip,\n",
    "    tokenizer=tokenizer,\n",
    "    cache_config=cache_cfg,\n",
    "    image_size=384,\n",
    ")\n",
    "rollout = vlm_rollout_lib.VLMRollout(\n",
    "    sampler=sampler,\n",
    "    pad_id=tokenizer.pad_id(),\n",
    "    eos_id=tokenizer.eos_id(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Rewards\n",
    "\n",
    "# %%\n",
    "reward_fns = [\n",
    "  R.match_format_exact,\n",
    "  R.match_format_soft,\n",
    "  (lambda **kw: R.exact_match(**kw, answer=kw[\"answer\"])),\n",
    "  (lambda **kw: R.fuzzy_contains(**kw, answer=kw[\"answer\"])),\n",
    "  (lambda **kw: R.numeric_tolerance(**kw, answer=kw[\"answer\"], rtol=0.02)),\n",
    "  R.brevity_penalty,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c925f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## RL cluster & GRPO\n",
    "\n",
    "# %%\n",
    "ckpt_opts = rl_cluster_lib.ocp.CheckpointManagerOptions(save_interval_steps=200, max_to_keep=4)\n",
    "mlog_opts = metrics_logger.MetricsLoggerOptions(log_dir=os.path.join(WORKDIR,\"tb\"), flush_every_n_steps=20)\n",
    "\n",
    "cluster_config = rl_cluster_lib.ClusterConfig(\n",
    "    role_to_mesh={\n",
    "        rl_cluster_lib.Role.ACTOR: mesh,\n",
    "        rl_cluster_lib.Role.REFERENCE: mesh,\n",
    "        rl_cluster_lib.Role.ROLLOUT: mesh,\n",
    "    },\n",
    "    rollout_engine=\"vlm\",\n",
    "    offload_to_cpu=False,\n",
    "    training_config=rl_cluster_lib.RLTrainingConfig(\n",
    "        actor_optimizer=optax.adamw(3e-6, b1=0.9, b2=0.99, weight_decay=0.1),\n",
    "        eval_every_n_steps=50,\n",
    "        max_steps=300,\n",
    "        gradient_accumulation_steps=1,\n",
    "        metrics_logging_options=mlog_opts,\n",
    "        checkpoint_root_directory=os.path.join(WORKDIR, \"ckpts\"),\n",
    "        checkpointing_options=ckpt_opts,\n",
    "    ),\n",
    "    rollout_config=base_rollout.RolloutConfig(\n",
    "        max_tokens_to_generate=MAX_GEN_STEPS,\n",
    "        max_prompt_length=MAX_PROMPT_LEN,\n",
    "        kv_cache_size=cache_cfg.cache_size,\n",
    "        temperature=0.9, top_p=1.0, top_k=50,\n",
    "    ),\n",
    ")\n",
    "\n",
    "rl_cluster = rl_cluster_lib.RLCluster(\n",
    "    actor=lora_text,\n",
    "    reference=ref_text,\n",
    "    tokenizer=tokenizer,\n",
    "    cluster_config=cluster_config,\n",
    "    rollout=rollout,\n",
    ")\n",
    "\n",
    "grpo = GrpoLearner(\n",
    "    rl_cluster=rl_cluster,\n",
    "    reward_fns=reward_fns,\n",
    "    grpo_config=GrpoConfig(num_generations=2, num_iterations=1, beta=0.08, epsilon=0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816db302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Dummy VQA iterator (replace with your dataset)\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "def dummy_iter(bs):\n",
    "  H = W = 384\n",
    "  img = np.ones((H,W,3), dtype=np.uint8) * 255\n",
    "  while True:\n",
    "    yield {\n",
    "      \"prompts\": [\"What is in the image? Answer in <answer>...</answer> format.\"] * bs,\n",
    "      \"image\": np.stack([img]*bs, axis=0),\n",
    "      \"answer\": [\"a blank white image\"] * bs,\n",
    "      \"question\": [\"What is in the image?\"] * bs,\n",
    "    }\n",
    "\n",
    "train_ds = dummy_iter(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe85a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "with mesh:\n",
    "  grpo.train(train_ds=train_ds, eval_ds=None, skip_jit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-tunix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
